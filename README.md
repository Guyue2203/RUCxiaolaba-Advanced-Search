# 🎯 人大小喇叭高级搜索系统

一个**极简高效**的智能搜索系统，专为中国人民大学小喇叭论坛设计。

## ✨ 项目特色

- 🚀 **极简架构**: 去除了复杂的DuckDB，直接使用Pandas处理CSV
- 🔍 **双模式搜索**: 精确搜索 + AI智能搜索
- ⚡ **高性能**: 简化的数据处理逻辑，响应更快
- 🛠️ **易维护**: 代码简洁清晰，易于理解和修改

## 🎯 核心功能

### 精确搜索
- 基于关键词的快速匹配
- 支持多关键词组合搜索
- 智能高亮显示匹配内容

### AI智能搜索  
- 使用阿里云通义千问进行智能分析
- 自然语言查询理解
- 智能总结和推荐

### 数据管理
- 自动数据爬取和更新
- 用户反馈收集
- 查询日志记录

## 🚀 快速开始

### 1. 环境准备
```bash
# 克隆项目
git clone <repository-url>
cd RUCxiaolaba-Advanced-Search

# 创建虚拟环境
python -m venv .venv

# 激活虚拟环境 (Windows)
.venv\Scripts\activate

# 激活虚拟环境 (Linux/Mac)
source .venv/bin/activate
```

### 2. 安装依赖
```bash
pip install -r requirements.txt
```

### 3. 配置API密钥
在 `utils.py` 中配置阿里云DashScope API密钥：
```python
# 在 ai_search 函数中
api_key='your-dashscope-api-key'
```

### 4. 启动服务
```bash
python app.py
```

访问地址: **http://localhost:8080** 🌐

## 📁 项目结构

```
RUCxiaolaba-Advanced-Search/
├── 🎯 核心文件
│   ├── app.py              # Flask主应用 (简化版)
│   ├── utils.py            # 工具函数 (简化版)
│   ├── spider.py           # 数据爬虫
│   └── requirements.txt    # 依赖包 (精简版)
├── 📊 数据目录
│   ├── all.csv            # 主数据文件
│   ├── crawl_config.json  # 爬取配置
│   ├── feedback.txt       # 用户反馈
│   └── query.txt          # 查询日志
├── 🎨 前端资源
│   ├── static/            # CSS/JS文件
│   └── templates/         # HTML模板
└── 📖 文档
    └── README.md          # 项目说明
```

## 🔧 技术架构

### 简化前后对比

| 组件 | 原版本 | 简化版本 | 改进 |
|------|--------|----------|------|
| 数据库 | DuckDB + 复杂SQL | 直接CSV + Pandas | ✅ 更简单 |
| 代码行数 | 359行 | 230行 | ✅ 减少36% |
| 依赖包 | 6个 | 4个 | ✅ 减少33% |
| 启动时间 | 需要初始化 | 即时启动 | ✅ 更快 |
| 维护难度 | 复杂 | 简单 | ✅ 易维护 |

### 核心技术栈
- **后端**: Flask + Python
- **数据处理**: Pandas (直接处理CSV)
- **AI服务**: 阿里云DashScope (通义千问)
- **前端**: HTML + CSS + JavaScript

## 🎮 使用指南

### 精确搜索
1. 选择"精确搜索"模式
2. 输入关键词（支持多个）
3. 查看高亮显示的匹配结果

### AI智能搜索
1. 选择"AI搜索"模式  
2. 输入自然语言查询
3. 获得AI智能分析和总结

### 数据更新
```bash
# 手动更新数据
python spider.py

# 自动更新 (每天凌晨3点)
# 系统会自动执行数据更新
```

### 数据管理
- **首次运行**: 从2024年9月1日开始爬取数据
- **增量更新**: 每次从上次爬取的末尾ID继续
- **配置管理**: 使用 `data/crawl_config.json` 记录爬取状态
- **数据存储**: 所有数据统一存储在 `data/all.csv` 中

## 🛠️ 开发说明

### 主要改进
1. **去除DuckDB**: 直接使用Pandas处理CSV，避免复杂的数据库操作
2. **简化搜索逻辑**: 使用字符串匹配替代复杂SQL查询
3. **优化错误处理**: 减少复杂的异常处理，提高代码可读性
4. **精简依赖**: 移除不必要的包，减少安装复杂度

### 性能优化
- 数据加载: 按需加载，避免内存浪费
- 搜索算法: 简化的字符串匹配，响应更快
- 错误处理: 优雅降级，提高系统稳定性

## 📈 功能规划

### 已完成 ✅
- [x] 基础搜索功能
- [x] AI智能搜索
- [x] 数据爬虫
- [x] 用户反馈系统
- [x] 维护模式
- [x] 架构简化

### 计划中 🚧
- [ ] 搜索历史记录
- [ ] 用户个性化设置
- [ ] 移动端适配
- [ ] 数据可视化
- [ ] 搜索结果缓存

## ❓ 常见问题

### Q: 为什么选择简化架构？
A: 原架构过于复杂，DuckDB对于这个规模的数据来说是大材小用。简化后更易维护，性能更好。

### Q: 如何更新数据？
A: 系统每天凌晨3点自动更新，也可手动运行 `python spider.py`

### Q: AI搜索不工作怎么办？
A: 检查API密钥配置和网络连接，确保DashScope服务正常

### Q: 数据量增大会影响性能吗？
A: 当前架构可以处理数万条数据，如果数据量继续增长，可以考虑添加缓存机制

## 🤝 贡献指南

欢迎提交Issue和Pull Request！

### 开发环境
```bash
# 安装开发依赖
pip install -r requirements.txt

# 运行测试
python app.py
```

## 📄 许可证

MIT License

---

**🎉 享受更简单、更高效的搜索体验！**